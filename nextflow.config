// ============================================================
// nextflow.config  –  Community structure analysis pipeline
// ============================================================

// ── Pipeline parameters (override with --param value on CLI) ─
params {
    // ── Required ──────────────────────────────────────────────
    // Path to counts CSV (rows = taxa, columns = samples)
    input           = null

    // Path to sample metadata CSV (rows = samples, must contain
    // a 'group' column with values e.g. PD / control)
    metadata        = null

    // ── Output ────────────────────────────────────────────────
    output_dir      = "results"

    // ── Taxonomy (optional) ───────────────────────────────────
    // Path to taxonomy CSV used by FastSpar for heatmap annotation
    // and cross-kingdom breakdown.
    // Expected columns: taxon_id, kingdom, phylum, class, order, family, genus
    taxonomy        = null

    // ── Reproducibility ───────────────────────────────────────
    seed            = 42
}

// ── Execution profiles ───────────────────────────────────────
profiles {

    // default: run every process inside the microbe-comm-struct Docker image
    docker {
        docker.enabled    = true
        docker.runOptions = "-v ${projectDir}:/workspace"

        process {
            container = "microbe-comm-struct:latest"

            // Default resource allocation per process
            cpus   = 2
            memory = "4 GB"
            time   = "2 h"

            withName: 'AITCHISON_PCA' {
                cpus   = 2
                memory = "8 GB"
                time   = "1 h"
            }

            withName: 'RPCA_DEICODE' {
                cpus   = 2
                memory = "16 GB"
                time   = "2 h"
            }

            // FastSpar calls an external binary and runs 1000 bootstraps.
            // Unfiltered family-level data (~1963 taxa) needs >8 GB for the
            // 1963x1963 co-occurrence matrix across 1000 bootstrap iterations.
            // QEMU emulation adds overhead, so threads capped at 8 to keep
            // per-thread memory manageable on the 128 GB DGX Spark host.
            withName: 'FASTSPAR' {
                cpus   = 8
                memory = "48 GB"
                time   = "8 h"
            }

            withName: 'NETWORK_NULL' {
                cpus   = 10
                memory = "4 GB"
                time   = "1 h"
            }
        }
    }

    // local: skip Docker (assumes R + all packages are installed locally)
    local {
        docker.enabled = false
        process.executor = 'local'
    }

    // slurm: submit to a SLURM cluster, still using the Docker image via
    // Singularity (common on HPC).  Adjust queue/account as needed.
    slurm {
        process.executor    = 'slurm'
        singularity.enabled = true
        singularity.autoMounts = true

        process {
            container = "docker://microbe-comm-struct:latest"
            queue     = "short"
            cpus      = 4
            memory    = "16 GB"
            time      = "12 h"

            withName: 'AITCHISON_PCA' {
                cpus   = 2
                memory = "8 GB"
                time   = "1 h"
            }

            withName: 'RPCA_DEICODE' {
                cpus   = 2
                memory = "16 GB"
                time   = "2 h"
            }

            withName: 'FASTSPAR' {
                cpus   = 8
                memory = "16 GB"
                time   = "8 h"
            }

            withName: 'NETWORK_NULL' {
                cpus   = 2
                memory = "4 GB"
                time   = "2 h"
            }
        }
    }
}

// ── Nextflow reporting ───────────────────────────────────────
report {
    enabled   = true
    overwrite = true
    file      = "${params.output_dir}/pipeline_report.html"
}

timeline {
    enabled   = true
    overwrite = true
    file      = "${params.output_dir}/pipeline_timeline.html"
}

trace {
    enabled   = true
    file      = "${params.output_dir}/pipeline_trace.txt"
    overwrite = true
    fields    = 'task_id,name,status,exit,realtime,cpus,%cpu,memory,%mem,rss'
}

dag {
    enabled = true
    file    = "${params.output_dir}/pipeline_dag.html"
}
